Version 1.0.0:
==============
Architecture Design for Particle Filter:

Input:
1- Number of Particles
2- Feature Name + Similarity Measure + Gaussian Variance
3- Occlusion Flag Threshold

Particle Filter:
1- Initialize
	1-1- Initialize First Bounding Box
    1-2- Initialize Parameters
    1-3- Initialize Particles
    1-4- Initialize Target Model (Calculate Features Based on RGB + Depth + Init BB)
2- Particle Filter Train
3- Particle Filter Test Loop
    3-1- Calculate Features 
    3-2- Measure Particle Features to Target
    3-3- Calculate Particle Likelihood Based on Feature
    3-4- Normalize Features Between All Particles
    3-5- Calculate Particle Likelihood via Log-Sum-Exp
    3-6- Normalize Particle Likelihood to Make Probability
    3-7- Apply Occlusion Flag
    3-8- Update Target Model
    3-9- Resampling




Version 0.3.0:
==============
1- Naive trackers (lower bound and upper bound trackers)

VERSION 0.2.0:
==============
1- General Framework Planning:

* General Settings
* Training
*** For Each Video Do
****** Read Video General Info
****** Initialize Trackers for Training Mode
****** For Each Frame of Video Do
********* For Each Tracker Do
************ Provide Tracker with Input Data and Ground Truth
****** Returning & Saving the Trained Parameters of Tracker / If No Video is Provided Load Default Values
* Testing
*** For Each Video Do
****** Read Video General Info
****** Initialize Trackers for Testing Mode: with Trained Parameters, Hand Tuned Parameters (Same Algorithm with Different Set of Parameters),
****** For Each Frame of Video Do
********* For Each Tracker Do
************ Provide Tracker with Input Data
************ Save the Result of Tracking
*** Returning The Result for Each Video
* Evaluations
*** For Each Video Do
****** For Each Tracker Do
********* Calculate the Evaluation Metrics
****** Draw Result Table
* Output Generation
*** Save Overall Tracking Video
*** Save Tracker Result Files

VERSION 0.1.0:
==============
1- Read data from Princeton dataset





REQUIREMENTS:
=============

* Variuos Detection Modes
1- Color Only
2- Depth only
3- Color and Depth

* Input Data from Public dataset

* Occlusion Handling
1- Princeton 

* Occlusion Detection
1- Based on D
	1-1- Depth Histogram Two Peaks
2- Based on RGB
3- Based on Trackers Information Exchange
4- Track Occluder
5- Detect Partial Caption

* Run Different Trackers Simultaneously & Assign Different Colors to Them

* Target Initialization
1- By Hand
2- Text File
3- Detector Algorithm

* Pre-processing
1- Background Subtraction
	1-1- Using GMM for FG & BG
	1-2- Using Temporal Median Background
2- Shadow Removal
3- Illumination Normalization
4- Blurring of Depth Map

* 2D Features
1- Color Feature -> Histogram of Colors
	1-1- Using K-Means & RGB Histogram
	1-2- Using Fixed Grid & RGB Histogram
	1-3- Using Fixed Grid & HSV Histogram
	1-4- Using GMM for Target
2- Advanced Feature
	2-1- HOG
	2-2- SIFT
	2-3- PCA-SIFT
	2-4- Edge Orientation Histogram
	2-5- Shape Contexts
	2-6- Haar Wavelet
	2-7- R-HOG
	2-8- C-HOG
	2-9- R2-HOG
	2-10- E-ShapeC
	2-11- G-ShapeC
	2-12- SURF
3- Textural Features
4- Segmentation
	4-1- Color Clusters Adjacency Graph

* 3D Features
1- Histogram of Colors in Color Namespace
2- Points Count in the Cell
3- 3D Shape Feature
	3-1- Scatterness
	3-2- Linearness
	3-3- Surfaceness

* Depth Features
1- Median of Depth
2- Histogram of Depth
3- Histogram of Oriented Depth (HOD)

* Motion Features
1- Optical Flow
2- Mihaylon Paper

* Distance Measures -> To be used in Gaussian 
1- Point-to-Point Euclidean Distance
2- Mahalanobis Distance
3- Bhattacherya Distance
4- KL Divergance

* Enable Train and Test Mode
1- Train: Learning Confidence, Tuning Parameters, ...
2- Test: Seeing The Results

* Enable Online Learning
1- Target Model
	1-1- Supervised Learning -> N-P Learning
	1-2- Statistically -> Weighted Mean Sliding Window
2- Occlusion Cases
3- State Transition Model
4- Confidence Map
5- Background

* Switching Between RGB and D Channels
1- Different Confidence Measures
2- Linear Sum of RGB and D -> Adaptive Weights
3- Using Occlusion detection

* Evaluation of Results
1- CLEAR MOT: MOTA, MOTP
2- PASCAL VOC: R, ...
3- Object Center Position Error(CPE)
4- Scale Error: SA

* Evaluation Curves:
1- ROC
2- DET: error-tradeoff log-log sclae (miss rate vs. false positive)
3- Average Success rate vs. Threshold of Overlap ratio (r_t)




TECHNICAL FEATURES:
===================
* Start Video from a Given Frame

* Organized Source Code into Folders

* Verbose Report

* Saving Video of Results

* Save Result Bounding Boxes in the File

* Parameters of Tracker
1- Number of Particles, Features, Similarity Measures, Gaussian Variance, Occlusion Flag Threshold, ...
2- Run Each Tracker with its own set of parameters.

* Stable Bounding Box Around The Target (Do not shake or jitter)

* Visualization
1- Input Data: Color Channel, Depth Channel, Point Cloud, ...
2- Tracking History and Ground Truth: Type of Errors, Source of Errors, ...
3- Particle Dynamics: Color Histogram, Local Features (e.g. iHOG), Depth Map, Confidence Map, Distance to Template, ...
4- Tracker Dynamics: All Particles, Expected New Target, Occlusion Suspects, Ground Truth, Background Update, Template Update, Probability Histogram of Particles (including probability of ground truth), Learnt Smaples, ...
5- All Objects Silhouette Image
6- Stabilized Picture
